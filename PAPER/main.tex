\documentclass[oribibl]{llncs}
\input{includes/preamble.tex}

\begin{document}
	
\title{Heuristics for the Score-Constrained Strip-Packing Problem}
\author{Asyl L. Hawa \and Rhyd M. R. Lewis \and Jonathan M. Thompson}
\institute{School of Mathematics, Cardiff University, Senghennydd Road, Cardiff, UK, CF24 4AG}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
\label{sec:intro}
Firstly, let us introduce the Constrained Ordering Problem:

\begin{definition}
	\label{defn:cop}
	Let $\mathcal{M}$ be a multiset of unordered pairs of positive integers $\mathcal{M} = \{\{a_1, b_1\}, \{a_2,b_2\},...,\{a_n,b_n\}\}$, and let $\mathcal{T}$ be an ordering of the elements of $\mathcal{M}$ such that each element is a tuple. The Constrained Ordering Problem (COP) consists of finding a solution $\mathcal{T}$ such that, given a fixed value $\tau \in \mathbb{Z}^{+},$
	\begin{equation}
		\label{eqn:vsc}
		\textup{\textbf{rhs}}(i) + \textup{\textbf{lhs}}(i+1) \geq \tau \hspace{5mm} \forall \hspace{1mm} i \in \{1,2,..., n-1\},
	\end{equation}
	where \textup{\textbf{lhs}($i$)} and \textup{\textbf{rhs}($i$)} denote the left- and right-hand values of the $i$th tuple. The inequality is referred to as the \textup{vicinal sum constraint}.
\end{definition}

For example, given the multiset $\mathcal{M} = \{\{1,2\}, \{1,7\}, \{2,4\}, \{3,5\}, \{3,6\}, \{4,4\}\}$ and $\tau = 7$, one possible feasible solution is $\mathcal{T} = \langle(1,2), (6,3), (5,3), (4,4), (4,2), (7,1) \rangle$.

One prominent application of the COP is in a strip-packing problem brought to light as an open-combinatorial problem by \citeauthor{goulimis2004} in 2004. A set $\mathcal{I}$ of rectangular items of equal height $H$ made from cardboard are to be packed onto a strip of height $H$ from left to right. Each item $i \in \mathcal{I}$ has width $w_i \in \mathbb{Z}^{+}$, and possesses two vertical score lines, marked in predetermined places. A pair of knives mounted onto a bar cuts along the score lines of two adjacent items simultaneously, which allows the items to be folded with ease (see Figure \ref{fig:itemsknife}). However, by design, the scoring knives cannot be placed too close to one another, and as such have a ``minimum scoring distance'' (around 70mm in industry). The distances between each score line and the nearest edge on an item $i \in \mathcal{I}$ are the score widths, $a_i, b_i \in \mathbb{Z}^{+}$, assigned such that $a_i \leq b_i$. Since these score widths are not necessarily equal, an item $i$ can be positioned in one of two orientations: ``regular'', denoted $(a_i, b_i)$, or ``rotated'', denoted $(b_i, a_i)$, where the smaller of the two score widths $a_i$ is on the left- and right- hand side of the item respectively. Clearly, for two items to be placed alongside one another feasibly, the sum of the adjacent score widths must equal or exceed the minimum scoring distance, else the knives will not be able to score the items in the correct locations. Thus, the problem consists of finding a suitable ordering and orientation of the items such that the sum of every pair of adjacent score widths is greater than or equal to the minimum scoring distance. Specifically, as the items are packed from left to right, this involves checking the sum of the right-hand score width of each item $i$ and the left-hand score width of the next item $i+1$ on the strip. The left-hand score width of the first item and the right-hand score width of the last item on the strip are not adjacent to any other item, and are therefore ignored. 

\begin{figure}[h!]	
	\centering
	\includestandalone[width=0.8\textwidth]{figures/itemsknife}
	\caption{Dimensions of an item $i \in \mathcal{I}$ in a regular orientation $(a_i, b_i)$, and a feasible alignment of two items that can be scored simultaneously.}	
	\label{fig:itemsknife}
\end{figure}


It can be seen that this problem is in fact analogous to the COP, where each unordered pair in an instance $\mathcal{M}$ contains values corresponding to the score widths of an item, and $\tau$ is the minimum scoring distance. Thus, a set $\mathcal{I}$ of items has a feasible arrangement if the equivalent COP has a solution $\mathcal{T}$ that meets the vicinal sum constraint.

Observe that, in this particular strip-packing problem, the widths of the individual items are disregarded entirely, since the aim is to arrange the items onto a strip of seemingly infinite width. In practical applications, strips of material are often provided in fixed widths. Given a large problem instance, multiple strips may therefore be required to feasibly accommodate all of the items. For this reason, we define a new problem to be investigated.

\begin{definition}
	\label{defn:scspp}
	Let $\mathcal{S} = \{S_1, S_2, ..., S_k\}$ be a set of strips of height $H$ and width $W$, and let $\mathcal{I}$ be a set of rectangular items of height $H$ and varying widths $w_i \in \mathbb{Z}^+ < W$ and score widths $a_i, b_i \in \mathbb{Z}^+$ such that $a_i \leq b_i$ and $a_i + b_i < w_i$ for each item $i \in \mathcal{I}$. Given a minimum scoring distance $\tau \in \mathbb{Z}^+$, the Score-Constrained Strip-Packing Problem (SCSPP) consists of finding the minimum number of strips $k$ required to pack all items in $\mathcal{I}$ such that the sum of every pair of adjacent score widths is greater than or equal to $\tau$.
\end{definition}

The SCSPP is a generalisation of the classical one-dimensional bin-packing problem (BPP), where in the latter problem the minimum scoring distance $\tau$ can be said to be equal to zero. It follows that the SCSPP is at least as hard as the BPP, which is known to be NP-hard (\citealp{garey1979}), and so (under the assumption that $P \neq NP$) there is no known algorithm that is able to find an optimal solution for every instance of the SCSPP in polynomial time. Instead, heuristics can be used to find near-optimal solutions in a shorter amount of time.

\begin{definition}
	\label{defn:subprob}
	Let $\mathcal{I}' \subseteq \mathcal{I}$ be a set of items whose total width is less than or equal to the capacity of a strip, (i.e. $\sum_{i=1}^{|\mathcal{I}'|}w_i \leq W$). Given a minimum scoring distance $\tau$, the Score-Constrained Packing Sub-Problem (SCPSP) involves finding an arrangement of the items in $\mathcal{I}'$ such that the sum of every pair of adjacent score widths is greater than or equal to $\tau$.
\end{definition}

The remainder of this article will firstly, in Section 2, detail a polynomial-time algorithm that is able to produce a solution to any instance of the COP, if a solution exists. Section 3 describes three heuristics that can be used to find feasible solutions to the SCSPP, and discusses the associated advantages and disadvantages. A comparison of these heuristics and an analysis of the results will be provided in Section 4, and finally Section 5 concludes the paper and proposes some potential directions for future work.

\section{Solving the COP}
\label{sec:ahca}
We shall now present an algorithm for solving the COP in polynomial time. The original(underlying) algorithm was created by \cite{becker2010}, and determines whether or not a solution exists for a given instance. We have extended this algorithm so that, if a solution does indeed exist, the algorithm is able to formulate and present us with this final solution. This is especially useful for problems such as the previously mentioned strip-packing problem, where a tangible solution is required in order to place the items in the correct order and orientation.
% We shall now present an algorithm for solving the COP, which operates by expressing the problem instance graphically. 

Let $\mathcal{M}$ be an instance of the COP of cardinality $n$. We model each of the values of all elements in $\mathcal{M}$ as a vertex on a graph $G$, and assign each vertex a value from $\mathcal{M}$ in non-decreasing order. A pair of vertices, called ``dominating vertices'' are then added to the graph, both of which are assigned values equal to $\tau$. These dominating vertices aid the solution process, and are removed at the end. Thus, the graph $G$ has $2n+2$ vertices.

The values in $\mathcal{M}$, and thus the vertices on $G$, are arranged in pairs. This is represented on $G$ by adding a set of ``blue'' edges, $B$, that contains edges between vertices that are ``partners'', i.e. whose values make up a pair in $\mathcal{M}$. It can be seen that $B$ is a perfect matching, with $|B|= n+1$. Let the bijective function $p: V \to V$ associate each vertex with its partner, $p(v_i) = v_j$. Hence $B = \{(v_i, p(v_i)) : v_i \in V\}$

Next, a set of ``red'' edges $R$ is added to $G$ that consists of edges between vertices whose values equal or exceed $\tau$, provided they are not partners. This corresponds to the vicinal sum constraint in Defintion \ref{defn:cop}. 

Thus, we have an undirected graph $G$ with vertex set $V = \{v_1, ..., v_{2n+2}\}$ and two distinct edge sets $B$ and $R$ such that $B \cap R = \emptyset$. Figure \ref{fig:partners/threshold} illustrates the construction of $G$ using the instance $\mathcal{M}$ from the example above.
% Equation $v_i + v_j \geq \tau$ provided $p(v_i) \neq v_j$, i.e. not partners
% Values are assigned from $\mathcal{M}$ in non-decreasing order, i.e. value assoc with v_1 \leq value assoc with v_2 etc..

\begin{figure}	
\centering
\begin{subfigure}[h]{0.45\textwidth}
	\includestandalone[width=\textwidth]{figures/partners}
	\caption{$G = (V, B)$}	
	\label{fig:partners}
\end{subfigure} \hspace{40pt}
\begin{subfigure}[h]{0.45\textwidth}
	\includestandalone[width=\textwidth]{figures/threshold}
	\caption{$G=(V, B \cup R)$}	
	\label{fig:threshold}
\end{subfigure}
\caption{Construction of $G$ using instance $\mathcal{M} = \{\{1,2\}, \{1,7\}, \{2,4\}, \{3,5\}, \{3,6\}, \{4,4\}\}$ and $\tau = 7$, where $v_{13}$ and $v_{14}$ are the dominating vertices.}
\label{fig:partners/threshold}
\end{figure}

Recall that a Hamiltonian cycle on a graph $G$ is a cycle that visits every vertex exactly once. Now, consider the following definition describing a variant of the classical Hamiltonian cycle involving multiple edge sets.
\begin{definition}
	\label{defn:althamcycle}
	Let $G(V, B\cup R)$ be an undirected graph, where each edge is a member of one of two sets, $B$ or $R$. $G$ contains an alternating Hamiltonian cycle if there exists a Hamiltonian cycle such that successive edges alternate between sets $B$ and $R$. For example, if $(v_{i-1}, v_i) \in B$, then $(v_i, v_{i+1}) \in R$, or vice versa.
\end{definition}

An alternating Hamiltonian cycle on $G$ would correpsond to a feasible solution, as each ``blue'' edge from $B$ represents a pair of values in $\mathcal{M}$, and each ``red'' edge from $R$ shows values that can be placed alongside one another feasibly. Thus, by removing the dominating vertices and any incident edges, the remaining alternating Hamiltonian path illustrates the order in which the elements should be placed to produce a feasible solution $\mathcal{T}$.

Since the values in each unordered pair in $\mathcal{M}$ cannot be altered, i.e. the values cannot be changed and the values in each element cannot be separated, every edge in $B$ must be present in the alternating Hamiltonian cycle. Consequently, the task now involves finding a matching $R' \subseteq R$ of cardinality $n+1$ such that the edge sets $B$ and $R'$ form an alternating Hamiltonian cycle as described in Definition \ref{defn:althamcycle}. 

To find a matching $R' \subseteq R$, the following \textsc{Maximum Cardinality Matching} (MCM) algorithm can be executed, as suggested by \cite{mahadev1994} and \cite{becker2010}: For each vertex $v_i, i=1,2,...,2n+2$, select the edge in $R$ connecting $v_i$ to the highest indexed vertex $v_j$ that is not already incident to an edge in $R'$. Add this edge $(v_i, v_j)$ to $R'$, and proceed to the next vertex until all the vertices have been assessed. The two vertices incident to each matching edge in $R'$ are now referred to as being ``matched''. Similarly to partners, let $m : V \to V$ be a bijective function that assigns each vertex with its match, $m(v_i) = v_j$. Then, $R' =\{(v_i, m(v_i)) : v_i \in V\}$. 

During MCM, if a vertex $v_i$ is not adjacent to any other unmatched vertex except its partner $p(v_i)$, the preceeding vertex $v_{i-1}$ can be ``rematched'', provided that 
\begin{enumerate*}[label={(\alph*)}]
	\item $v_i$ is not the first vertex; 
	%\item $v_{i-1} \in R'$; and
	\item $(v_{i-1}, m(v_{i-1})) \in R'$; and
	\item $(v_{i-1}, p(v_i)) \in R$.
\end{enumerate*}
Then, $v_i$ is matched with the vertex that is currently matched with $v_{i-1}$, i.e $m(v_i) = m(v_{i-1})$, and $v_{i-1}$ is rematched with $p(v_i)$, i.e. $m(v_{i-1}) = p(v_i)$. It is guaranteed that MCM will produce a maximum cardinality matching $R' \subseteq R$, and is able to do so in at most $O(n \log n)$ time (\citealp{mahadev1994}).

\begin{figure}	
	\centering
	\begin{subfigure}[h]{0.4\textwidth}
		\includestandalone[width=\textwidth]{figures/matching}
		\caption{$G' = (V, B \cup R')$}	
		\label{fig:matching}
	\end{subfigure} \quad
	\begin{subfigure}[h]{0.5\textwidth}
		\includestandalone[width=\textwidth]{figures/mps}
		\caption{Planar representation of $G' =(V, B \cup R')$}	
		\label{fig:mps}
	\end{subfigure}
	\caption{Spanning subgraph $G'$ consisting of a matching set $R' \subseteq R$ derived using MCM. The planar representation shows $G'$ comprises $q = 2$ components.}
	\label{fig:matching/mps}
\end{figure}

Clearly, if $|R'| < n+1$, there are not enough matching edges to form an alternating Hamiltonian cycle along with the edges in $B$, and hence no feasible solution can be found for the given instance $\mathcal{M}$ of the COP. Otherwise, if $R'$ is a perfect matching of cardinality $n+1$, the spanning subgraph $G'=(V, B \cup R')$ is a 2-regular graph, where each vertex is adjacent to its partner via an edge in $B$, and its match via an edge in $R'$ (see Figure \ref{fig:matching/mps}). $G'$ thus consists of a collection of alternating cycles $C_1, C_2, ..., C_q$. In the case where $G'$ comprises one component, i.e. $q = 1$, then this alternating cycle is in fact Hamiltonian, and therefore a feasible solution exists. However, if $q > 1$, the components of $G'$ must be combined to form an alternating Hamiltonian cycle. To do this, a \textsc{Bridge Recognition} (BR) algorithm can be executed that selects suitable edges from $R$ that will replace certain edges in $R'$ in order to function as bridges and connect the components of $G'$.

The edges in $R'$ are sorted into a list such that the lower-indexed vertices of each edge are in increasing order and the higher-indexed vertices are in decreasing order, i.e. $(v_1, v_{2n+2}), (v_2, v_{2n+1}), ..., (v_{n+1}, v_{n+2})$. Any edges that cannot be placed in such an order are then removed from this list. For instance, in the example illustrated in Figure \ref{fig:matching/mps}, $(v_5, v_9)$ would be removed from the list, since the next edge in the list is $(v_6, v_{10})$, and so the higher-indexed vertices are not in decreasing order. This is due to $v_5$ not being matched with the highest-indexed vertex available $v_{10}$ during MCM, as $(v_5, v_{10}) \in B$.

Starting from the first edge, BR searches through the list to find an edge that meets the following conditions: 
\begin{enumerate*}[label={(\alph*)}]
	\item The lower-indexed vertex of the current edge and the higher-indexed vertex of the next edge in the list are adjacent via an edge in $R$; and
	\item The current edge and the next edge are members of different components on $G'$.
\end{enumerate*}

If the conditions are met, BR adds the current edge to a set $R_i$, and continues to add all succeeding edges in the list to $R_i$, provided that for each edge both conditions hold, and the succeeding edge is not a member of a component of $G'$ that has an edge in $R_i$. Once there are no more valid edges available to add to $R_i$, BR resumes its search through the remaining edges in the list to find a new edge that meets the conditions, and can begin a new set $R_{i+1}$. The procedure terminates once the penultimate edge in the list has been assessed, having generated the sets $R_1, R_2, ..., R_k \subseteq R'$.

In the event that BR has been unable to produce a single set, i.e. $k = 0$, there are no suitable edges that can combine the components $C_1, C_2, ..., C_k$ of $G'$, and therefore an alternating Hamiltonian cycle cannot be created. Thus, no feasible solution exists for the given instance of the COP.

If there exists a set $R_i$ such that $|R_i| = q$, then the components of $G'$ can be merged together to form a single alternating Hamiltonian cycle. This is achieved by adding the red edge connecting the lower-indexed vertex of each edge in $R_i$ to the higher-indexed vertex of the next edge to $R'$ (for the final edge in $R_i$, add the red edge connecting its lower-indexed vertex to the higher-indexed vertex of the first edge). Any edges that appear in both $R_i$ and $R'$ are then removed from $R'$, so that $R'$ remains a perfect matching, and $R_i \cap R' = \emptyset$. $G'$ then consists of a single alternating Hamiltonian cycle, and hence a solution has been found.

Otherwise, if $k > 1$, it may be that multiple sets are required to connect all components of $G'$. For two sets $R_i$ and $R_j$ to ``overlap'', each set must have one edge from the same component on $G'$, and the other edges in each set must be from different components. For example, if $R_1$ has two edges, one from component $C_1$ and one from component $C_2$, and $R_2$ has three edges that are members of $C_2$, $C_3$ and $C_4$, then $R_1$ and $R_2$ are said to overlap, since they each possess an edge $C_2$, and the other edges in the sets are from different components. Hence, a selection of sets from $R_1, R_2, ..., R_k$ need to be found such that each set overlaps with at least one other set, and each component has at least one edge in one of the selected sets. If such a collection of sets exists, then the components of $G$ can be merged to create an alternating Hamiltonian cycle by applying the connecting procedure above to every set in the collection.
% Refer to figures

This algorithm, which will be referred to as the \textsc{Alternating Hamiltonian Construction Algorithm} (AHCA) is able to deduce whether a feasible solution $\mathcal{T}$ exists for any given instance $\mathcal{M}$ of the COP. If a solution does indeed exist, AHCA can produce this solution in at most $O(n^2)$ time.
% Cite Becker

\begin{figure}	
	\centering
	\begin{subfigure}[H]{0.5\textwidth}
		\includestandalone[width=\textwidth]{figures/mpsconnect}
		\caption{Edges from $R\backslash R'$ can connect vertices from different cycles.}	
		\label{fig:mpsconnect}
	\end{subfigure}
	\begin{subfigure}[H]{0.5\textwidth}
		\includestandalone[width=\textwidth]{figures/mpscycle}
		\caption{Replacing edges connects the components and forms an alternating Hamiltonian cycle.}	
		\label{fig:mpscycle}
	\end{subfigure}
	\caption{Selected edges found using BR merge the components of $G'$ together, forming an alternating Hamiltonian cycle which corresponds to a feasible solution $\mathcal{T} = \langle(1,2), (6,3), (5,3), (4,4), (4,2), (7,1) \rangle$.}
	\label{fig:connect/cycle}
\end{figure}


\begin{theorem}
	\label{thm:copsoln}
	There exists a feasible solution $\mathcal{T}$ to an instance $\mathcal{M}$ of the COP if and only if its corresponding graph $G=(V, B\cup R)$ contains an alternating Hamiltonian cycle.
\end{theorem}
\begin{proof}
	Let $\mathcal{A} = \{v_1, v_2, ..., v_{2n+1}, v_{2n+2}\}$ be an alternating Hamiltonian cycle on $G$, where $v_{2n+1}$ and $v_{2n+2}$ are the dominating vertices. By definition, $\mathcal{A}$ contains all vertices on $G$, and all $n+1$ edgs in $B$. Thus, there exists a set of $n+1$ edges from $R$ that, together with the edges in $B$, form the alternating Hamiltonian cycle. Now, removing the dominating vertices and any incident edges gives rise to an alternating Hamiltonian path $\mathcal{A}' = \{v_1, v_2, ..., v_{2n-1}, v_{2n}\}$, whose first edge $(v_1, v_2)$ and last edge $(v_{2n-1}, v_{2n})$ are in $B$. The order of the values corresponding to each vertex of this path form a feasible solution $\mathcal{T}$, where values that are partners make up a tuple.\qed
\end{proof}


\section{Heuristics for the SCSPP}
\label{sec:scsppsoln}

(Why heuristics, using AHCA for SCSPP, explain) Perhaps the simplest and most well-known heuristic for packing problems is \textsc{First-Fit} (FF), a greedy online algorithm that places each item presented in some arbitrary order onto the lowest-indexed strip such that the capacity of the strip is not exceeded. It is known that there always exists at least one ordering of the items such that FF produces an optimal solution (\citealp{lewis2009}). A minor modification to FF yields the \textsc{First-Fit Decreasing} (FFD) heuristic, which sorts the items in non-increasing order of size prior to performing FF.

For an instance of the SCSPP, a feasible solution is represented by the set $\mathcal{S} = \{S_1, S_2, ..., S_k\}$ such that
\begin{subequations}
	\begin{align}
		\bigcup\nolimits_{j=1}^{|\mathcal{S}|} S_j &= \mathcal{I}, \label{eqn:packall}\\[3pt]
		S_j \cap S_l &= \emptyset \hspace{5mm} \forall \hspace{1mm} j, l \in \{1, 2, ..., |\mathcal{S}|\}, \hspace{2mm} j \neq l, \label{eqn:nooverlap} \\[3pt]
		\sum\nolimits_{i=1}^{|S_j|}w_i & \leq W \hspace{3mm} \forall \hspace{1mm} S_j \in \mathcal{S}, \label{eqn:capacity} \\[3pt]
		\textup{\textbf{rhs}}(i) + \textup{\textbf{lhs}}(i+1) &\geq \tau \hspace {5mm} \forall \hspace{1mm} i \in \{1, 2, ..., |S_j|-1\}, \hspace{2mm} \forall \hspace{1mm} S_j \in \mathcal{S}. \label{eqn:vscstrip}
\end{align}
\end{subequations}

That is, all items must be packed onto a strip, each item can only be placed on one strip, the strips cannot be overpacked, and the items on each strip $S_j$ in the solution must be arranged such that the sum of two adjacent score widths is greater than or equal to the minimum scoring distance $\tau$.

An optimal solution $\mathcal{S}$ of an instance of the SCSPP is a solution that consists of the fewest number of strips $k$. A simple lower bound for $k$ that can be computed in $O(n)$ time is given by 
\begin{equation}
\label{eqn:lowerbound}
k \geq \ceil*{\frac{\sum_{i=1}^{n}w_i}{W}},
\end{equation}
where $n$ is the number of items ($|\mathcal{I}|$), $w_i$ the width of each item $i \in \mathcal{I}$, and $W$ is the width of the strips (\citealp{martello1990b}). In 1973, \citeauthor{johnson1973} showed that FFD is guaranteed to return a solution that uses no more than $\frac{11}{9}k + 4$ strips. More recently, \cite{dosa2007} has proven that the worst case for FFD is in fact $\frac{11}{9}k + \frac{6}{9}$, and that this bound is tight. Due to the initial sorting of the $n$ items in non-increasing order of sizes, the time complexity of FFD is $O(n\log n)$.

As mentioned in the introduction, the SCSPP shares many similarities with the BPP, however the addition of constraint (\ref{eqn:vscstrip}) induces complications that must be taken into consideration. One obvious difference is the order in which the items must appear on the strips. In the BPP, removing an item retains feasibility, whereas in the SCSPP this is not guaranteed, as the constraint may not be fulfilled between the two score widths either side of the item removed. Furthermore, lower bound for $k$ (Equation (\ref{eqn:lowerbound})) does not hold for the SCSPP, as the minimum scoring distance $\tau$ is not included in the calculation. For example, if $\tau > 2 \max(b_i)$ (that is, the minimum scoring distance is greater than twice the largest score width), then it is clear that $n$ strips will be required, regardless of the items' widths.
% Time complexity for FFD also inaccurate

Three heuristics for the SCSPP have been developed: a basic FFD heuristic with a simple modification; a heuristic that packs strips individually and prioritises score widths; and a powerful version of FFD that incorporates the polynomial-time AHCA algorithm.

\subsection{Modified First-Fit Decreasing Heuristic (MFFD)}
\label{sec:mffd}
The \textsc{Modified First-Fit Decreasing} (MFFD) heuristic performs in the same manner as the original FFD, attempting to place each item onto the end of the lowest-indexed strip. If an item is able to be packed onto a strip without exceeding the strip's capacity, MFFD then checks to see if the vicinal sum constraint is met between the right-most score on the strip and one of the score widths on the current item. If the constraint is met, MFFD places the item on the end of the strip in the appropriate orientation, else the heuristic attempts to pack the item onto the next lowest-indexed strip. For example, in Figure \ref{fig:comparestrips}, the strip is able to accommodate the current item, however the vicinal sum constraint is not fulfilled in either orientation of the item, and therefore it cannot be feasibly packed onto the strip.

Despite the additional step, MFFD is a very fast heuristic, as checking the vicinal sum constraint can be performed in constant time. The most prominent issue with this heuristic, however, is due to the items being placed on the end of the strips. Although an item may not meet the constraint when placed on the end of a strip, there may be another location on the strip where the item can be placed feasibly. MFFD is incapable of placing items anywhere other than on the end of the strips, and so an item that could potentially be packed must be placed on another strip, or perhaps even begin a new strip, thus increasing the number of strips in the final solution.


\subsection{Pair-Smallest Heuristic (PS)}
\label{sec:ps}

The \textsc{Pair-Smallest} (PS) heuristic is an extension of a procedure defined by \cite{lewis2011}. Unlike MFFD, which packs each item in turn, PS focusses on packing one strip at a time, only starting a new strip once the current strip is unable to accommodate any more items feasibly. Each strip is initialised by choosing the item from $\mathcal{I}$ with the smallest score width, and packing it in a regular orientation. PS then continues to fill the strip by selecting the item with the smallest score width that meets the vicinal sum constraint with the right-most score width on the strip, and whose width will not cause the strip to be overfilled. This heuristic aligns the smallest score widths with the largest ones, eliminating the possibility of placing larger score widths together unecessarily. Note that PS prioritises the vicinal sum constraint over the item widths, choosing to fulfil the constraint first before considering whether the item can be accommodated. If there are multiple items with equal score widths, break ties by choosing the item whose second score width is the largest.
% Break ties by choosing item whose second score width is larger.
% If item with smallest feasible score width does not fit onto the strip, choose item with next smallest score width and repeat.



\subsection{Modified First-Fit Decreasing with AHCA (MFFD$^+$)}
\label{sec:mffd+}

The last heuristic incorporates AHCA as described in Section \ref{sec:ahca}. The \textsc{Modified First-Fit Decreasing with AHCA} (MFFD$^+$) heuristic operates in a similar fashion to the MFFD, placing items sorted in decreasing order onto the lowest-indexed strip. However, when the lowest-indexed strip is found that can accommodate the current item, MFFD$^+$ then executes AHCA on the sub-problem, where the items on the strip and the current item form the subset $\mathcal{I}' \subseteq \mathcal{I}$ (see Definition \ref{defn:subprob}). If AHCA finds a feasible solution, the items are placed on the strip in the order of the solution, which includes the current item, else MFFD$^+$ attempts to pack the current item on the next lowest-indexed strip. Using AHCA means that if a feasible alignment of the items exists, there is a guarantee that it will be found. Unlike MFFD, where the current item can only be placed on the end of the strip, MFFD$^+$ allows the items to be entirely rearranged (see Figure \ref{fig:comparestrips}). This reduces the possibility of having to start a new strip for an item, thus preventing increasing the number of strips in the final solution.


\begin{figure}[h!]	
	\centering
	\includestandalone[width=\textwidth]{figures/strips}
	\caption{Comparison of MFFD and MFFD$^+$, $W = 20$, $\tau = 70$.}	
	\label{fig:comparestrips}
\end{figure}


\section{Comparison}
\begin{itemize}
	\item Heuristics implemented in C++ and executed on a computer equipped with an Intel Core i3-2120 processor with a frequency of 3.30GHz.
	\item $n$ = 100, 500, and 1000, number of items in $\mathcal{I}$, $W$ = 5000, 2500, 1250, item widths uniform dist [150, 1000], score widths uniform dist [1,70] (ensures each item has two score widths that do not overlap), all items and strips have height H ( = 1)
	\item Changing strip length changes the average number of items per strip (why is this important?) Harder problems have fewer items per strip
	\item run each instance 1000 times (per value of $\delta$), same instances each time.
	\item table shows optimality, which is the number of strips in the final solution generated by the heuristic divided by the number of strips in the optimal solution (which is calculated using the lower bound for $k$ above), =1 then optimal
	\item Goulimis stated n= 10, this is able to find solutions for n=1000
	\item graph showing time or optimality of all three heuristics
	\item $\delta$ is proportion of score widths that meet VSC (excluding partners and itself), 0.1 increments.
	\item changing the value of $\tau$ changes the proportion of the number of score widths
	\item if $\delta = 0.0$, then no score widths can be aligned number of strips = $n$, $\delta = 1.0$, then all score widths can be aligned with any other score width, BPP.
	\item As the strip length is decreased, MFFD+ improves, number of items/strip decreases
	\item when $\delta = 1.0$ MFFD and MFFD+ will perform in the same manner (like original FFD)
	\item PS does not reach highest optimality at $\delta = 0.8$ onwards in any strip length
	\item as avg number of items per strip decreases, PS is less efficient, MFFD+ is better
	\item note anomaly in $n = 1000, W = 1250, \delta = 0.3$, MFFD performs the best.
\end{itemize}

\begin{table}[!htb]
	\centering
	\caption{$n = 100$}
	\begin{tabular}{c@{\hspace{15pt}}c@{\hspace{10pt}}c@{\hspace{10pt}}c@{\hspace{7pt}}| @{\hspace{7pt}}c@{\hspace{10pt}}c@{\hspace{10pt}}c@{\hspace{7pt}}| @{\hspace{7pt}} c@{\hspace{10pt}}c@{\hspace{10pt}}c}
		\noalign{\smallskip}
		& \multicolumn{3}{c}{$W = 5000$} & \multicolumn{3}{c}{$W = 2500$} & \multicolumn{3}{c}{$W = 1250$} \\
		\hline\noalign{\smallskip}
		$\delta$ & MFFD & PS & MFFD$^+$ & MFFD & PS & MFFD$^+$ & MFFD & PS & MFFD$^+$ \\
		\noalign{\smallskip}
		\hline 
		\noalign{\smallskip}
		0.0	& 8.35709 & 8.35709 & 8.35709 & 4.26800 & 4.26800 & 4.26800 & 2.15624 & 2.15624 & 2.15624 \\
		0.1	& 5.27284 & \textbf{4.89963} & 5.14404 & 2.72299 & \textbf{2.48800} & 2.69191 & 1.53147 & \textbf{1.51049} & 1.52968 \\
		0.2	& 4.16155 & \textbf{3.46467} & 3.98645 & 2.21096 & \textbf{1.87449} & 2.16338 & 1.34812 & \textbf{1.34499} & 1.34593 \\
		0.3	& 3.27805 & \textbf{2.40153} & 3.05546 & 1.82199 & \textbf{1.43724} & 1.75610 & 1.22453 & 1.24810 & \textbf{1.21994} \\
		0.4	& 2.61641 & \textbf{1.63390} & 2.33662 & 1.54989 & \textbf{1.16887} & 1.46534 & 1.14507 & 1.19631 & \textbf{1.13979} \\
		0.5	& 2.08260 & \textbf{1.13827} & 1.77494 & 1.35101 & \textbf{1.04978} & 1.25567 & 1.09274 & 1.17069 & \textbf{1.08661} \\
		0.6	& 1.65897 & \textbf{1.02027} & 1.36093 & 1.20040 & \textbf{1.03720} & 1.11964 & 1.06255 & 1.15766 & \textbf{1.05701} \\
		0.7	& 1.32002 & \textbf{1.01350} & 1.11348 & 1.09659 & \textbf{1.03556} & 1.04569 & 1.04546 & 1.14416 & \textbf{1.04150} \\
		0.8	& 1.10725 & \textbf{1.01384} & 1.02188 & 1.03577 & 1.03439 & \textbf{1.01696} & 1.03711 & 1.12951 & \textbf{1.03565} \\
		0.9	& 1.02134 & 1.01315 & \textbf{1.00646} & 1.01364 & 1.03285 & \textbf{1.01029} & 1.03434 & 1.11631 & \textbf{1.03416} \\
		1.0 & \textbf{1.00480} & 1.01302 & \textbf{1.00480} & \textbf{1.00919} & 1.03261 & \textbf{1.00919} & \textbf{1.03393} & 1.10807 & \textbf{1.03393} \\	
		\hline
	\end{tabular}
	\label{table:n100}
\end{table}

\begin{table}[!htb]
	\centering
	\caption{$n = 500$}
	\begin{tabular}{c@{\hspace{15pt}}c@{\hspace{10pt}}c@{\hspace{10pt}}c@{\hspace{7pt}}| @{\hspace{7pt}}c@{\hspace{10pt}}c@{\hspace{10pt}}c@{\hspace{7pt}}| @{\hspace{7pt}} c@{\hspace{10pt}}c@{\hspace{10pt}}c}
		\noalign{\smallskip}
		& \multicolumn{3}{c}{$W = 5000$} & \multicolumn{3}{c}{$W = 2500$} & \multicolumn{3}{c}{$W = 1250$} \\
		\hline\noalign{\smallskip}
		$\delta$ & MFFD & PS & MFFD$^+$ & MFFD & PS & MFFD$^+$ & MFFD & PS & MFFD$^+$ \\
		\noalign{\smallskip}
		\hline
		\noalign{\smallskip}
		0.0 & 8.61813 & 8.61813 & 8.61813 & 4.32789 & 4.32789 & 4.32789 & 2.16858 & 2.16858 & 2.16858 \\
		0.1 & 5.21367 & \textbf{4.84177} & 5.16085 & 2.65934 & \textbf{2.47735} & 2.65679 & 1.51486 & \textbf{1.47896} & 1.51486 \\
		0.2 & 4.03055 & \textbf{3.45946} & 3.97645 & 2.12099 & \textbf{1.84737} & 2.11788 & 1.32613 & \textbf{1.31781} & 1.32610 \\
		0.3 & 3.11091 & \textbf{2.34803} & 3.03816 & 1.72955 & \textbf{1.39676} & 1.70772 & 1.19451 & 1.22922 & \textbf{1.19381} \\
		0.4 & 2.43605 & \textbf{1.52907} & 2.29713 & 1.45976 & \textbf{1.12798} & 1.40951 & 1.11037 & 1.18065 & \textbf{1.10819} \\
		0.5 & 1.91057 & \textbf{1.04130} & 1.69129 & 1.26343 & \textbf{1.03341} & 1.19575 & 1.05771 & 1.15415 & \textbf{1.05319} \\
		0.6 & 1.49086 & \textbf{1.01263} & 1.24645 & 1.12448 & \textbf{1.02957} & 1.06874 & 1.02932 & 1.13470 & \textbf{1.02398} \\
		0.7 & 1.19571 & \textbf{1.01257} & 1.04468 & 1.04933 & 1.02774 & \textbf{1.01918} & 1.01741 & 1.11368 & \textbf{1.01444} \\
		0.8 & 1.04977 & 1.01203 & \textbf{1.00815} & 1.01595 & 1.02661 & \textbf{1.00790} & 1.01297 & 1.09136 & \textbf{1.01197} \\
		0.9 & 1.00929 & 1.01197 & \textbf{1.00463} & 1.00734 & 1.02586 & \textbf{1.00641} & 1.01159 & 1.07283 & \textbf{1.01139} \\
		1.0 & \textbf{1.00423} & 1.01171 & \textbf{1.00423} & \textbf{1.00626} & 1.02561 & \textbf{1.00626} & \textbf{1.01130} & 1.06549 & \textbf{1.01130} \\		
		\hline
	\end{tabular}
	\label{table:n500}
\end{table}	


\begin{table}[!htb]
	\centering
	\caption{$n = 1000$}
	\begin{tabular}{c@{\hspace{15pt}}c@{\hspace{10pt}}c@{\hspace{10pt}}c@{\hspace{7pt}}| @{\hspace{7pt}}c@{\hspace{10pt}}c@{\hspace{10pt}}c@{\hspace{7pt}}| @{\hspace{7pt}} c@{\hspace{10pt}}c@{\hspace{10pt}}c}
		\noalign{\smallskip}
		& \multicolumn{3}{c}{$W = 5000$} & \multicolumn{3}{c}{$W = 2500$} & \multicolumn{3}{c}{$W = 1250$} \\
		\hline\noalign{\smallskip}
		$\delta$ & MFFD & PS & MFFD$^+$ & MFFD & PS & MFFD$^+$ & MFFD & PS & MFFD$^+$ \\
		\noalign{\smallskip}
		\hline
		\noalign{\smallskip}
		0.0 & 8.65711 & 8.65711 & 8.65711 & 4.33803 & 4.33803 & 4.33803 & 2.17138 & 2.17138 & 2.17138 \\
		0.1 & 5.17263 & \textbf{4.84248} & 5.14027 & 2.63606 & \textbf{2.48111} & 2.64271 & 1.51056 & \textbf{1.46744} & 1.51121 \\
		0.2 & 3.97565 & \textbf{3.46163} & 3.95164 & 2.09301 & \textbf{1.85824} & 2.10161 & 1.31785 & \textbf{1.31090} & 1.31876 \\
		0.3 & 3.04866 & \textbf{2.35023} & 3.01260 & 1.69777 & \textbf{1.40862} & 1.68776 & \textbf{1.18304} & 1.22111 & 1.18344 \\
		0.4 & 2.37436 & \textbf{1.52046} & 2.26560 & 1.42646 & \textbf{1.13101} & 1.38430 & 1.09722 & 1.17063 & \textbf{1.09614} \\
		0.5 & 1.84748 & \textbf{1.02600} & 1.64169 & 1.22960 & \textbf{1.03017} & 1.16950 & 1.04411 & 1.14430 & \textbf{1.03986} \\
		0.6 & 1.43331 & \textbf{1.01212} & 1.20264 & 1.09935 & \textbf{1.02738} & 1.05010 & 1.01971 & 1.12392 & \textbf{1.01480} \\
		0.7 & 1.15500 & \textbf{1.01198} & 1.02574 & 1.03421 & 1.02569 & \textbf{1.01224} & 1.01150 & 1.10164 & \textbf{1.00926} \\
		0.8 & 1.03182 & 1.01182 & \textbf{1.00587} & 1.01111 & 1.02454 & \textbf{1.00682} & 1.00861 & 1.07791 & \textbf{1.00804} \\
		0.9 & 1.00707 & 1.01165 & \textbf{1.00419} & 1.00663 & 1.02406 & \textbf{1.00608} & 1.00784 & 1.05885 & \textbf{1.00774} \\
		1.0 & \textbf{1.00399} & 1.01169 & \textbf{1.00399} & \textbf{1.00603} & 1.02400 & \textbf{1.00603} & \textbf{1.00770} & 1.05406 & \textbf{1.00770} \\
		\hline
	\end{tabular}
	\label{table:n1000}
\end{table}	

\textbf{$n$ = 100}
\begin{itemize}
	\item Average total item width = 57466.776, $\sigma$ = 2499.06092
	\item $W = 5000$, Average LB = 11.993, $\sigma$ = 0.56829
	\item $W = 2500$, Average LB = 23.478, $\sigma$ = 1.05618
	\item $W = 1250$, Average LB = 46.466, $\sigma$ = 2.02703
\end{itemize}

\textbf{$n$ = 500}
\begin{itemize}
	\item Average total item width = 287683.855, $\sigma$ = 5434.63046
	\item $W = 5000$, Average LB = 58.039, $\sigma$ = 1.12227
	\item $W = 2500$, Average LB = 115.571, $\sigma$ = 2.18150
	\item $W = 1250$, Average LB = 230.648, $\sigma$ = 4.35041
\end{itemize}

\textbf{$n$ = 1000}
\begin{itemize}
	\item Average total item width = 575163.174, $\sigma$ = 7880.93401
	\item $W = 5000$, Average LB = 115.534, $\sigma$ = 1.59463
	\item $W = 2500$, Average LB = 230.563, $\sigma$ = 3.16734
	\item $W = 1250$, Average LB = 460.623, $\sigma$ = 6.30895
\end{itemize}

\textbf{Speed $n$ = 500}
\begin{itemize}
	\item MFFD $W = 5000$ Average speed = 38.88504ms/instance
	\item MFFD $W = 2500$ Average speed = 38.55795ms/instance
	\item MFFD $W = 1250$ Average speed = 37.98091ms/instance
	\item PS $W = 5000$ Average speed = 42.11938ms/instance
	\item PS $W = 2500$ Average speed = 44.24521ms/instance
	\item PS $W = 1250$ Average speed = 49.66614ms/instance
	\item MFFD$^+$ $W = 5000$ Average speed = 214.04479ms/instance
	\item MFFD$^+$ $W = 2500$ Average speed = 190.36579ms/instance
	\item MFFD$^+$ $W = 1250$ Average speed = 214.78729ms/instance
\end{itemize}

\textbf{Speed $n$ = 1000}
\begin{itemize}
	\item MFFD $W = 5000$ Average speed = 159.68755ms/instance
	\item MFFD $W = 2500$ Average speed = 
	\item MFFD $W = 1250$ Average speed = 
	\item PS $W = 5000$ Average speed = 
	\item PS $W = 2500$ Average speed = 
	\item PS $W = 1250$ Average speed = 
	\item MFFD$^+$ $W = 5000$ Average speed = 
	\item MFFD$^+$ $W = 2500$ Average speed = 
	\item MFFD$^+$ $W = 1250$ Average speed = 
\end{itemize}




\bibliographystyle{dcu}
\bibliography{includes/bibliography}

\end{document}